{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([ToTensor(), Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, persistent_workers=True)\n",
    "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2, persistent_workers=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbeddings(pl.LightningModule):\n",
    "    def __init__(self, in_channels = 3, patch_size = 8, embedding_dim = 128):\n",
    "        super().__init__()\n",
    "        self.unfolding = nn.Unfold(kernel_size = patch_size, stride = patch_size)\n",
    "        self.projection = nn.Linear(in_channels * patch_size ** 2 , embedding_dim)\n",
    "                \n",
    "    def forward(self,x):\n",
    "        x = self.unfolding(x) # H * W * C -> N * ( P * P * C)\n",
    "        x = x.transpose(1, 2) # N * ( P * P * C) -> N * ( P * P * C)\n",
    "        x = self.projection(x) # N * ( P * P * C) -> N * E\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(pl.LightningModule):\n",
    "    def __init__(self, dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        assert dim % n_heads == 0 # dim must be divisible by n_heads\n",
    "        self.head_dim = dim // n_heads\n",
    "        \n",
    "        self.K = nn.Linear(in_features=dim, out_features=dim)\n",
    "        self.Q = nn.Linear(in_features=dim, out_features=dim)\n",
    "        self.V = nn.Linear(in_features=dim, out_features=dim)\n",
    "\n",
    "        self.out_proj = nn.Linear(in_features=dim, out_features=dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        K = self.K(x)\n",
    "        Q = self.Q(x)\n",
    "        V = self.V(x)\n",
    "        \n",
    "        K = K.view(x.shape[0], x.shape[1], self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        Q = Q.view(x.shape[0], x.shape[1], self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(x.shape[0], x.shape[1], self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        attention = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attention = torch.nn.functional.softmax(attention, dim=-1)\n",
    "        x = torch.matmul(attention, V)\n",
    "        \n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.dim)\n",
    "        x = self.out_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, in_features, hidden_features, out_features, dropout=0.1, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=hidden_features)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_features, out_features=out_features)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.activation = activation()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(pl.LightningModule):\n",
    "    def __init__(self, dim, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln_pre_attn = nn.LayerNorm(dim)\n",
    "        self.attention = MultiHeadAttention(dim, n_heads)\n",
    "        self.ln_pre_ffn = nn.LayerNorm(dim)\n",
    "        self.ffn = MLP(dim, dim * 4, dim, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.ln_pre_attn(x))\n",
    "        x = x + self.ffn(self.ln_pre_ffn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(pl.LightningModule):\n",
    "    def __init__(self, in_channels = 3, patch_size = 4, embedding_dim = 256, n_blocks = 6 , n_heads = 8, out_dim = 10, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Patch Embeddings\n",
    "        self.patch_embeddings = PatchEmbeddings(in_channels = in_channels, patch_size = patch_size, embedding_dim = embedding_dim)\n",
    "        \n",
    "        # Positional Embeddings\n",
    "        num_patches = (32 // patch_size) ** 2\n",
    "        self.positional_embeddings = nn.Parameter(torch.randn(1, 1 + num_patches, embedding_dim))\n",
    "        \n",
    "        # Class Token\n",
    "        self.class_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.transformer_encoder = nn.Sequential(*[TransformerEncoder(embedding_dim, n_heads, dropout) for _ in range(n_blocks)])\n",
    "        \n",
    "        # MLP Head\n",
    "        self.mlp_head = MLP(embedding_dim, embedding_dim * 4, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embeddings(x)\n",
    "        x = torch.cat([self.class_token.expand(B, -1, -1), x], dim=1)\n",
    "        x = x + self.positional_embeddings\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, 0]\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "    \n",
    "    def _shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.CrossEntropyLoss(label_smoothing=0.1)(y_hat, y)\n",
    "        return loss, y_hat, y\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss,y_hat, y = self._shared_step(batch, batch_idx)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('train_accuracy', acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y_hat, y = self._shared_step(batch, batch_idx)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_accuracy', acc, prog_bar=True, on_epoch=True)\n",
    "        return {'val_loss': loss, 'val_accuracy': acc}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y_hat, y = self._shared_step(batch, batch_idx)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_accuracy', acc, prog_bar=True)\n",
    "        return {'test_loss': loss, 'test_accuracy': acc}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type            | Params\n",
      "--------------------------------------------------------\n",
      "0 | patch_embeddings    | PatchEmbeddings | 12.5 K\n",
      "1 | transformer_encoder | Sequential      | 4.7 M \n",
      "2 | mlp_head            | MLP             | 273 K \n",
      "  | other params        | n/a             | 16.9 K\n",
      "--------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.166    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b152dc2281eb44d7a4766d813b7d8006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018921158ec4b3bb4ceb0b54bda8fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e1c189d1394b9b87cf1981d4f51f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4571f53ab94e47862d9bde25003e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d351db9828bf4030a970fdd4647e1e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8070be2f19f40c0b04eb461d5947eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714608aaf67e497c877206d55176492f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa95c21dd75247cdac6e92659b7bd521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccbe570859a438795bca79765a62ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d558322971441699d23d2ff9daefa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e49e65f49444435a5ebd904360ae686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54e3b6ff40b49109b549a8f4cbf79e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed146a0c19ef46f7a2491d0d45670a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae19a5de43594903b25cf0fb0db139fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f585c417147b49a58da959609fecfa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a5da40cc2045df80fa359f95c35879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5683950e703422bac560ff71730f942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6524c1493244bd89e3703a7264f2b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81f4c65b66b4e55a58f21f7f2a252ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de44952543734467acc278baea666f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff78932b42a4580a8b4054262a11214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535b65e360b64e7e92e130a3e84876df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6743c2d0174c2991842c849edad17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d8f9d431c84b8ca728e2d20a7b81c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db985212cf0146febb0de47e905baa6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88cc7fe9471447c89691c71e85b3d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1d81ddb47a4be291ab59e7974c151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb9a049b2334a5994b753af67c2de76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abff291da70c44919dddd93fbb4c9da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f1c0090874a17885907134acb1d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e49c29b8f904d9fa373b3a7eabfd359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2414e4a9ad1e483494973bbcee629c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a05b6a64d704b26bd64d6cb3143d071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4c834bc78e4f65b24a5d0b20b97523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4535569d5ca748729f3a4c9ec49dcdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eithannakache/Desktop/ViT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"ViT\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,                  \n",
    "    logger=logger,                  \n",
    ")\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=trainloader, val_dataloaders=valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
